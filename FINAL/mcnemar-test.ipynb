{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T04:21:39.156395Z",
     "iopub.status.busy": "2025-04-26T04:21:39.156104Z",
     "iopub.status.idle": "2025-04-26T04:23:11.383071Z",
     "shell.execute_reply": "2025-04-26T04:23:11.382384Z",
     "shell.execute_reply.started": "2025-04-26T04:21:39.156374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 images belonging to 4 classes.\n",
      "\n",
      "Predicting with baseline model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745641305.489124      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1745641305.489964      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745641308.511749     100 service.cc:148] XLA service 0x7bddec003530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745641308.512781     100 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1745641308.512823     100 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1745641308.639429     100 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/200\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 94ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745641310.494486     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 177ms/step\n",
      "Saved predictions: y_pred_baseline.npy\n",
      "\n",
      "Predicting with gan85 model...\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step\n",
      "Saved predictions: y_pred_gan85.npy\n",
      "\n",
      "Predicting with gan75 model...\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step\n",
      "Saved predictions: y_pred_gan75.npy\n",
      "\n",
      "Predicting with gan72 model...\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step\n",
      "Saved predictions: y_pred_gan72.npy\n",
      "\n",
      "Predicting with gan70 model...\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step\n",
      "Saved predictions: y_pred_gan70.npy\n",
      "\n",
      "Predicting with gan65 model...\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step\n",
      "Saved predictions: y_pred_gan65.npy\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "val_dir = '/kaggle/input/augmented-alzheimer-mri-dataset-v2/data/val'\n",
    "\n",
    "\n",
    "image_size = (176, 208)\n",
    "batch_size = 32\n",
    "SEED = 42\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='sparse',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "\n",
    "y_true = val_gen.classes\n",
    "np.save('y_true.npy', y_true)\n",
    "\n",
    "\n",
    "model_paths = {\n",
    "    'baseline':'/kaggle/input/cnn_base_latest/keras/default/1/alzheimers_augmented_model_latest.h5',\n",
    "    'gan85': '/kaggle/input/cnn_augmented_dcgan/keras/default/1/cnn_model_augmented_85.h5',\n",
    "    'gan75': '/kaggle/input/cnn_augmented_dcgan/keras/default/1/cnn_model_augmented_75.h5',\n",
    "    'gan72': '/kaggle/input/cnn_augmented_dcgan/keras/default/1/cnn_model_augmented_72.h5',\n",
    "    'gan70': '/kaggle/input/cnn_augmented_dcgan/keras/default/1/cnn_model_augmented_70.h5',\n",
    "    'gan65': '/kaggle/input/cnn_augmented_dcgan/keras/default/1/cnn_model_augmented_65.h5'\n",
    "}\n",
    "\n",
    "\n",
    "for name, path in model_paths.items():\n",
    "    print(f\"\\nPredicting with {name} model...\")\n",
    "    model = load_model(path)\n",
    "    val_gen.reset()\n",
    "    preds = model.predict(val_gen, verbose=1)\n",
    "    y_pred = np.argmax(preds, axis=1)\n",
    "    np.save(f'y_pred_{name}.npy', y_pred)\n",
    "    print(f\"Saved predictions: y_pred_{name}.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T04:25:29.691977Z",
     "iopub.status.busy": "2025-04-26T04:25:29.691125Z",
     "iopub.status.idle": "2025-04-26T04:25:29.702511Z",
     "shell.execute_reply": "2025-04-26T04:25:29.701857Z",
     "shell.execute_reply.started": "2025-04-26T04:25:29.691951Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " McNemar’s Test Results (vs. Baseline Model):\n",
      "\n",
      "Comparing Baseline vs GAN85:\n",
      "  Contingency: [[0, 116], [80, 0]]\n",
      "  χ² = 6.2500, p = 0.0124\n",
      "Statistically significant improvement (p < 0.05)\n",
      "\n",
      "Comparing Baseline vs GAN75:\n",
      "  Contingency: [[0, 117], [81, 0]]\n",
      "  χ² = 6.1869, p = 0.0129\n",
      "Statistically significant improvement (p < 0.05)\n",
      "\n",
      "Comparing Baseline vs GAN72:\n",
      "  Contingency: [[0, 28], [93, 0]]\n",
      "  χ² = 33.8512, p = 0.0000\n",
      "Statistically significant improvement (p < 0.05)\n",
      "\n",
      "Comparing Baseline vs GAN70:\n",
      "  Contingency: [[0, 261], [66, 0]]\n",
      "  χ² = 115.0948, p = 0.0000\n",
      "Statistically significant improvement (p < 0.05)\n",
      "\n",
      "Comparing Baseline vs GAN65:\n",
      "  Contingency: [[0, 247], [86, 0]]\n",
      "  χ² = 76.8769, p = 0.0000\n",
      "Statistically significant improvement (p < 0.05)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y_true = np.load('y_true.npy')\n",
    "\n",
    "\n",
    "model_names = ['gan85', 'gan75', 'gan72', 'gan70', 'gan65']\n",
    "\n",
    "\n",
    "y_pred_baseline = np.load('y_pred_baseline.npy')\n",
    "\n",
    "print(\"\\n McNemar’s Test Results (vs. Baseline Model):\")\n",
    "\n",
    "\n",
    "for name in model_names:\n",
    "    y_pred_gan = np.load(f'y_pred_{name}.npy')\n",
    "\n",
    "        \n",
    "    baseline_correct = (y_pred_baseline == y_true)\n",
    "    gan_correct = (y_pred_gan == y_true)\n",
    "\n",
    "    # McNemar contingency table values\n",
    "    b = np.sum((baseline_correct == True) & (gan_correct == False))  # Baseline only correct\n",
    "    c = np.sum((baseline_correct == False) & (gan_correct == True))  # GAN only correct\n",
    "\n",
    "    # Contingency table: [ [a, b], [c, d] ] but a & d not needed\n",
    "    table = [[0, b], [c, 0]]\n",
    "\n",
    "    # Run McNemar’s test\n",
    "    result = mcnemar(table, exact=False, correction=True)\n",
    "\n",
    "    print(f\"\\nComparing Baseline vs {name.upper()}:\")\n",
    "    print(f\"  Contingency: [[0, {b}], [{c}, 0]]\")\n",
    "    print(f\"  χ² = {result.statistic:.4f}, p = {result.pvalue:.4f}\")\n",
    "\n",
    "    if result.pvalue < 0.05:\n",
    "        print(\"Statistically significant improvement (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"Not statistically significant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2510229,
     "sourceId": 4259915,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 318445,
     "modelInstanceId": 297840,
     "sourceId": 357360,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 318463,
     "modelInstanceId": 297858,
     "sourceId": 357383,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 318813,
     "modelInstanceId": 298206,
     "sourceId": 357934,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
